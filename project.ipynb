{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/mohitgupta/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/mohitgupta/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import gensim\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn import preprocessing\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn import tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_data = pd.read_csv(\"train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "word2vec_model = gensim.models.KeyedVectors.load_word2vec_format('./GoogleNews-vectors-negative300.bin', binary=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "word2vec_model.similar_by_word(\"cancer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_word2vec(description, model):\n",
    "    description = str(description)\n",
    "    description = description.lower()\n",
    "    description = re.sub('[^a-zA-Z]', ' ', description )  \n",
    "    description = re.sub(r'\\s+', ' ', description)\n",
    "    description_tokens = nltk.sent_tokenize(description)\n",
    "    all_words = [nltk.word_tokenize(sent) for sent in description_tokens]\n",
    "    for i in range(len(all_words)):  \n",
    "        all_words[i] = [w for w in all_words[i] if w not in stopwords.words('english')]\n",
    "    if len(all_words) > 0:\n",
    "        all_words = all_words[0]\n",
    "    avg_word2vec_words = np.zeros(300)\n",
    "#     print (all_words)\n",
    "    for word in all_words:\n",
    "        if word in model:\n",
    "            avg_word2vec_words += model[word]\n",
    "        \n",
    "    return avg_word2vec_words  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def convert_text_col_word2vec(column, model):\n",
    "    col_vector_list = []\n",
    "    for description in column:\n",
    "        description_vector = get_word2vec(description, model)\n",
    "        col_vector_list.append(description_vector)\n",
    "    return np.array(col_vector_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def _run_nn(train_feature_matrix, train_label_matrix, test_feature_matrix):\n",
    "    nn_clf = MLPClassifier(solver='adam', alpha=1e-5, hidden_layer_sizes=(1500, 500), random_state=1)\n",
    "    nn_train_feature_matrix = train_feature_matrix.astype(np.float64)\n",
    "    nn_test_feature_matrix = test_feature_matrix.astype(np.float64)\n",
    "    nn_clf.fit(nn_train_feature_matrix, train_label_matrix)\n",
    "    nn_predictions = nn_clf.predict(nn_test_feature_matrix)\n",
    "    return nn_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def _run_svm(train_feature_matrix, train_label_matrix, test_feature_matrix):\n",
    "    clf = SVC(gamma='auto')\n",
    "    clf.fit(train_feature_matrix, train_label_matrix)\n",
    "    predicted_labels = clf.predict(test_feature_matrix)\n",
    "    return predicted_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def _run_dtree(train_feature_matrix, train_label_matrix, test_feature_matrix):\n",
    "    dt_clf = tree.DecisionTreeClassifier()\n",
    "    dt_clf = dt_clf.fit(train_feature_matrix, train_label_matrix)\n",
    "    dt_predictions = dt_clf.predict(test_feature_matrix)\n",
    "    return dt_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def calculate_macro_f1_score(predictions, true_labels):\n",
    "    true_positives = [0 for i in range(11)]\n",
    "    false_positives = [0 for i in range(11)]\n",
    "    false_negatives = [0 for i in range(11)]\n",
    "\n",
    "    if len(predictions) != len(true_labels):\n",
    "        print(\"bug in code, length of predictions should match length of true_labels\")\n",
    "        return None\n",
    "    for i in range(len(predictions)):\n",
    "        if predictions[i] == true_labels[i]:\n",
    "            true_positives[predictions[i]] += 1\n",
    "        else:\n",
    "            false_positives[predictions[i]] += 1\n",
    "            false_negatives[true_labels[i]] += 1\n",
    "\n",
    "    total_classes = 0\n",
    "    total_f1 = 0\n",
    "    for i in range(11):\n",
    "        if true_positives[i]==0 and false_positives[i]==0:\n",
    "            continue\n",
    "        elif true_positives[i]==0 and false_negatives[i]==0:\n",
    "            continue\n",
    "        prec = true_positives[i]*1.0/(true_positives[i] + false_positives[i])\n",
    "        recall = true_positives[i]*1.0/(true_positives[i]+false_negatives[i])\n",
    "        f1=0\n",
    "        if prec+recall != 0:\n",
    "            f1 = 2*prec*recall/(prec+recall)\n",
    "            total_classes += 1\n",
    "            total_f1 += f1\n",
    "    return total_f1/total_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def split_dataset(t_frac, random_state, dataset):\n",
    "    testset=dataset.sample(frac=t_frac,random_state=random_state)\n",
    "    trainset=dataset.drop(testset.index)\n",
    "    testset.to_csv(\"testSet.csv\", index = False)\n",
    "    trainset.to_csv(\"trainingSet.csv\", index = False)\n",
    "    return trainset, testset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def preprocess(data, model):\n",
    "    # name_vector_column = convert_text_col_word2vec(train_data['Name'])\n",
    "    description_vector_column = convert_text_col_word2vec(data['Description'], model)\n",
    "    delete_columns = ['Name','Description','PetID']\n",
    "    dataset = data.drop(delete_columns, axis=1)\n",
    "    # dataset = dataset.join(pd.DataFrame(name_vector_column), rsuffix='_name')\n",
    "    dataset = dataset.join(pd.DataFrame(description_vector_column), rsuffix='_description')\n",
    "    one_hot_columns = ['Breed1','Breed2','Type','Gender','Color1','Color2','Color3','Vaccinated','Dewormed','Sterilized',\n",
    "                       'Health','MaturitySize','State','RescuerID']\n",
    "    for column in one_hot_columns:\n",
    "        dataset=pd.get_dummies(dataset, columns=[column])\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_features_labels(dataset):\n",
    "    labels = dataset['AdoptionSpeed']\n",
    "    features = dataset.drop(['AdoptionSpeed'], axis=1)\n",
    "    return features, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dataset = preprocess(train_data, word2vec_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trainset, testset = split_dataset(0.3, 47, dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_features_matrix, train_label_matrix = get_features_labels(trainset)\n",
    "test_features, test_labels = get_features_labels(testset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "len(test_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_predictions(model_name, train_features_matrix, train_label_matrix, test_features):\n",
    "    predicted_labels = np.zeros(len(test_features))\n",
    "    if model_name == 'nn':\n",
    "        predicted_labels = _run_nn(train_features_matrix, train_label_matrix, test_features)\n",
    "    elif model_name == 'svm':\n",
    "        predicted_labels = _run_svm(train_features_matrix, train_label_matrix, test_features)\n",
    "    elif model_name == 'dtree':\n",
    "        predicted_labels = _run_dtree(train_features_matrix, train_label_matrix, test_features)\n",
    "    return predicted_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "models = ['svm','dtree','nn']\n",
    "predicted_labels_dict = {}\n",
    "\n",
    "for model in models:\n",
    "    start_time = time.time()\n",
    "    predicted_labels = get_predictions(model, train_features_matrix, train_label_matrix, test_features)\n",
    "    predicted_labels_dict[model]=predicted_labels\n",
    "    end_time = time.time() - start_time\n",
    "    print (model, \"time taken\", end_time)\n",
    "    print (model, \"micro f1 score\", f1_score(predicted_labels, test_labels.values,average='micro'))\n",
    "    print (model, \"accuracy score\", accuracy_score(predicted_labels, test_labels.values))\n",
    "    print (model, \"macro f1 score\", calculate_macro_f1_score(predicted_labels, test_labels.values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "models = ['nn']\n",
    "predicted_labels_dict = {}\n",
    "\n",
    "for model in models:\n",
    "    start_time = time.time()\n",
    "    predicted_labels = get_predictions(model, train_features_matrix, train_label_matrix, test_features)\n",
    "    predicted_labels_dict[model]=predicted_labels\n",
    "    end_time = time.time() - start_time\n",
    "    print (model, \"time taken\", end_time)\n",
    "    print (model, \"micro f1 score\", f1_score(predicted_labels, test_labels.values,average='micro'))\n",
    "    print (model, \"accuracy score\", accuracy_score(predicted_labels, test_labels.values))\n",
    "    print (model, \"macro f1 score\", calculate_macro_f1_score(predicted_labels, test_labels.values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_features_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dtree_clf = tree.DecisionTreeClassifier()\n",
    "svm_clf = SVC(kernel='linear', C=1, random_state=0)\n",
    "nn_clf = MLPClassifier(solver='adam', alpha=1e-5, hidden_layer_sizes=(1500, 500), random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.metrics import recall_score\n",
    "scoring = ['accuracy', 'f1_micro', 'f1_macro']\n",
    "\n",
    "scores = cross_validate(dtree_clf, train_features_matrix, train_label_matrix, scoring=scoring, cv=5, return_train_score=True)\n",
    "print (scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "scores = cross_validate(svm_clf, train_features_matrix, train_label_matrix, scoring=scoring, cv=5, return_train_score=True)\n",
    "print (scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import learning_curve\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "\n",
    "\n",
    "def plot_learning_curve(estimator, title, X, y, ylim=None, cv=None,\n",
    "                        n_jobs=None, train_sizes=np.linspace(.1, 1.0, 5), fig_name):\n",
    "    plt.figure()\n",
    "    plt.title(title)\n",
    "    if ylim is not None:\n",
    "        plt.ylim(*ylim)\n",
    "    plt.xlabel(\"Training examples\")\n",
    "    plt.ylabel(\"Score\")\n",
    "    train_sizes, train_scores, test_scores = learning_curve(\n",
    "        estimator, X, y, cv=cv, n_jobs=n_jobs, train_sizes=train_sizes)\n",
    "    train_scores_mean = np.mean(train_scores, axis=1)\n",
    "    train_scores_std = np.std(train_scores, axis=1)\n",
    "    test_scores_mean = np.mean(test_scores, axis=1)\n",
    "    test_scores_std = np.std(test_scores, axis=1)\n",
    "    plt.grid()\n",
    "\n",
    "    plt.fill_between(train_sizes, train_scores_mean - train_scores_std,\n",
    "                     train_scores_mean + train_scores_std, alpha=0.1,\n",
    "                     color=\"r\")\n",
    "    plt.fill_between(train_sizes, test_scores_mean - test_scores_std,\n",
    "                     test_scores_mean + test_scores_std, alpha=0.1, color=\"g\")\n",
    "    plt.plot(train_sizes, train_scores_mean, 'o-', color=\"r\",\n",
    "             label=\"Training score\")\n",
    "    plt.plot(train_sizes, test_scores_mean, 'o-', color=\"g\",\n",
    "             label=\"Cross-validation score\")\n",
    "\n",
    "    plt.legend(loc=\"best\")\n",
    "    plt.savefig(fig_name)\n",
    "    return plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_label_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "title = \"Learning Curves\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cv = ShuffleSplit(n_splits=10, test_size=0.3, random_state=0)\n",
    "plot_learning_curve(dtree_clf, title, train_features_matrix, train_label_matrix, cv=cv, n_jobs=4, 'cross_validation_learning_curve_dtree')\n",
    "\n",
    "# title = r\"Learning Curves (SVM, RBF kernel, $\\gamma=0.001$)\"\n",
    "# # SVC is more expensive so we do a lower number of CV iterations:\n",
    "# cv = ShuffleSplit(n_splits=10, test_size=0.2, random_state=0)\n",
    "# estimator = SVC(gamma=0.001)\n",
    "# plot_learning_curve(estimator, title, X, y, (0.7, 1.01), cv=cv, n_jobs=4)\n",
    "\n",
    "plt.show()\n",
    "# plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cv = ShuffleSplit(n_splits=5, test_size=0.3, random_state=0)\n",
    "plot_learning_curve(svm_clf, title, train_features_matrix, train_label_matrix,\n",
    "                    cv=cv, n_jobs=4, 'cross_validation_learning_curve_svm')\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cv = ShuffleSplit(n_splits=5, test_size=0.3, random_state=0)\n",
    "plot_learning_curve(nn_clf, title, train_features_matrix, train_label_matrix,\n",
    "                    cv=cv, n_jobs=4, 'cross_validation_learning_curve_nn')\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
