{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import gensim\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_data = pd.read_csv(\"train.csv\")\n",
    "model = gensim.models.KeyedVectors.load_word2vec_format('./GoogleNews-vectors-negative300.bin', binary=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "description_list=train_data['Description']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_word2vec(description):\n",
    "    description = description_list[0]\n",
    "    description = description.lower()\n",
    "    description = re.sub('[^a-zA-Z]', ' ', description )  \n",
    "    description = re.sub(r'\\s+', ' ', description)\n",
    "    description_tokens = nltk.sent_tokenize(description)\n",
    "    all_words = [nltk.word_tokenize(sent) for sent in description_tokens]\n",
    "    for i in range(len(all_words)):  \n",
    "        all_words[i] = [w for w in all_words[i] if w not in stopwords.words('english')]\n",
    "    all_words = all_words[0]\n",
    "    avg_word2vec_words = np.zeros(300)\n",
    "    for word in all_words:\n",
    "        avg_word2vec_words += model[word]\n",
    "        \n",
    "    return avg_word2vec_words\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_text_col_word2vec(column):\n",
    "    col_vector_list = []\n",
    "    for description in column:\n",
    "        description_vector = get_word2vec(description)\n",
    "        col_vector_list.append(description_vector)\n",
    "    return col_vector_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "description_vector_list = np.array(description_vector_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def _run_nn(train_feature_matrix, train_label_matrix, test_feature_matrix):\n",
    "    nn_clf = MLPClassifier(solver='adam', alpha=1e-5, hidden_layer_sizes=(50, 30), random_state=1)\n",
    "    nn_train_feature_matrix = train_feature_matrix.astype(np.float64)\n",
    "    nn_test_feature_matrix = test_feature_matrix.astype(np.float64)\n",
    "    nn_clf.fit(nn_train_feature_matrix, train_label_matrix)\n",
    "    nn_predictions = nn_clf.predict(nn_test_feature_matrix)\n",
    "    return nn_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def calculate_macro_f1_score(predictions, true_labels):\n",
    "    true_positives = [0 for i in range(11)]\n",
    "    false_positives = [0 for i in range(11)]\n",
    "    false_negatives = [0 for i in range(11)]\n",
    "\n",
    "    if len(predictions) != len(true_labels):\n",
    "        print(\"bug in code, length of predictions should match length of true_labels\")\n",
    "        return None\n",
    "    for i in range(len(predictions)):\n",
    "        if predictions[i] == true_labels[i]:\n",
    "            true_positives[predictions[i]] += 1\n",
    "        else:\n",
    "            false_positives[predictions[i]] += 1\n",
    "            false_negatives[true_labels[i]] += 1\n",
    "\n",
    "    total_classes = 0\n",
    "    total_f1 = 0\n",
    "    for i in range(11):\n",
    "        if true_positives[i]==0 and false_positives[i]==0:\n",
    "            continue\n",
    "        elif true_positives[i]==0 and false_negatives[i]==0:\n",
    "            continue\n",
    "        prec = true_positives[i]*1.0/(true_positives[i] + false_positives[i])\n",
    "        recall = true_positives[i]*1.0/(true_positives[i]+false_negatives[i])\n",
    "        f1=0\n",
    "        if prec+recall != 0:\n",
    "            f1 = 2*prec*recall/(prec+recall)\n",
    "            total_classes += 1\n",
    "            total_f1 += f1\n",
    "    return total_f1*100.0/total_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name_vector_column = convert_text_col_word2vec(train_data['Name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Code for Artificial Neural Network\n",
    "'''\n",
    "start_time = time.time()\n",
    "predicted_labels = _run_nn(train_feature_matrix, train_label_matrix, test_feature_matrix)\n",
    "end_time = time.time() - start_time"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
